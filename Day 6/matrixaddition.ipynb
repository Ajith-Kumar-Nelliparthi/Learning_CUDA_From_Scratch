{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYdJf2pWhq-w",
        "outputId": "d90a28ce-e2ee-450d-eafb-4317ea331923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing vectoraddby2.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vectoraddby2.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void add(const float *a, float *c, int size){\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    for(; idx<size; idx += blockDim.x * gridDim.x){\n",
        "        c[idx] = a[idx] + 2.0f; // add 2.0 to each element\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 10000;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // allocate memory on the host\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    float *h_c = (float *)malloc(size);\n",
        "\n",
        "    if (!h_a || !h_c) {\n",
        "        printf(\"Host memory allocation failed!\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    srand((unsigned int)time(NULL));   // seed for random number generation\n",
        "    // initialize input data\n",
        "    for(int i=0; i<N; i++){\n",
        "        h_a[i] = rand() % 100; // random values between 0 and 99\n",
        "    }\n",
        "\n",
        "    // allocate memory on the device\n",
        "    float *d_a, *d_c;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // copy data from host to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsperblock = 256;\n",
        "    int blocks = (N + threadsperblock - 1) / threadsperblock;\n",
        "    // kernel\n",
        "    add<<<blocks, threadsperblock>>>(d_a,d_c,N);\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess){\n",
        "        printf(\"CUDA error: %s\\n\", cudaGetErrorString(err));\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // cpy results back from device to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i=0; i<5; i++){\n",
        "        printf(\"%f + 2.0 = %f\\n\", h_a[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Free all Memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BwYl-YGhxlC"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 vectoraddby2.cu -o vectoraddby2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcUGYb56iFFA",
        "outputId": "51fcb7b6-caf5-4e8d-bc21-572907f2e17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89.000000 + 2.0 = 91.000000\n",
            "91.000000 + 2.0 = 93.000000\n",
            "87.000000 + 2.0 = 89.000000\n",
            "62.000000 + 2.0 = 64.000000\n",
            "25.000000 + 2.0 = 27.000000\n"
          ]
        }
      ],
      "source": [
        "!./vectoraddby2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abPznM5yiJon",
        "outputId": "13fc7c68-5033-438d-a73e-90bca60b16e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing arrayMulCPUvsGPU.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile arrayMulCPUvsGPU.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "#include <chrono>\n",
        "\n",
        "// Kernel\n",
        "__global__ void arrayMul(const float *a, const float *b, float *c, int size){\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    for(; idx < size; idx+= blockDim.x * gridDim.x){\n",
        "        c[idx] = a[idx] * b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void arrayMulCPU(const float *a, const float *b, float *c, int size){\n",
        "    for(int i=0; i<size; i++){\n",
        "        c[i] = a[i] * b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 10000;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {64, 128, 256};\n",
        "    const int numTests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    float *h_b = (float *)malloc(size);\n",
        "    float *h_c = (float *)malloc(size);\n",
        "    float *h_c_cpu = (float *)malloc(size);\n",
        "\n",
        "    for(int i=0; i<N; i++){\n",
        "        h_a[i] = rand() / (float)RAND_MAX;\n",
        "        h_b[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    arrayMulCPU(h_a, h_b, h_c_cpu, N);\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "    float cpu_time = std::chrono::duration<float, std::milli>(cpu_end - cpu_start).count();\n",
        "    printf(\"CPU execution time : %.3f ms\\n\", cpu_time);\n",
        "\n",
        "    for (int i=0; i< numTests; i++){\n",
        "        int threadsPerBlock = blockSizes[i];\n",
        "        int blocks = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        dim3 dimBlock(threadsPerBlock);\n",
        "        dim3 dimGrid(blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        arrayMul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n",
        "        cudaEventRecord(stop);\n",
        "\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess) {\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"GPU Time: %f ms\\n\", gpu_time);\n",
        "\n",
        "        cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        bool correct = true;\n",
        "        for(int j=0; j<N; j++){\n",
        "            if (fabs(h_c[j] - h_c_cpu[j]) > 1e-5) {\n",
        "                printf(\"verification failed at index %d: GPU = %.2f, CPU = %.2f\\n\", j, h_c[j], h_c_cpu[j]);\n",
        "                correct = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if (correct){\n",
        "            printf(\"Result verification: SUCCESS\\n\");\n",
        "            if(gpu_time > 0.0)\n",
        "                printf(\"speedup: %.2fX\\n\", cpu_time / gpu_time);\n",
        "        }\n",
        "\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    free(h_c_cpu);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biz--oRhZN1V"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 arrayMulCPUvsGPU.cu -o arrayMulCPUvsGPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skwcmjQkZWtz",
        "outputId": "d9ae95fc-a7cd-4e3e-f841-45b6fcb75ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU execution time : 0.058 ms\n",
            "\n",
            "Testing block size: 64 (blocks: 157)\n",
            "GPU Time: 0.916864 ms\n",
            "Result verification: SUCCESS\n",
            "speedup: 0.06X\n",
            "\n",
            "Testing block size: 128 (blocks: 79)\n",
            "GPU Time: 0.015136 ms\n",
            "Result verification: SUCCESS\n",
            "speedup: 3.80X\n",
            "\n",
            "Testing block size: 256 (blocks: 40)\n",
            "GPU Time: 0.012992 ms\n",
            "Result verification: SUCCESS\n",
            "speedup: 4.43X\n"
          ]
        }
      ],
      "source": [
        "!./arrayMulCPUvsGPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7gO0ByWZZGb",
        "outputId": "ec25bd3a-b885-4d64-9381-0bb9789f6374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting matrixAddition.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrixAddition.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel for matrix addition\n",
        "__global__ void matrixAdd(const float *a, float *b, float *c, int rows, int cols){\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int stride_x = blockDim.x * gridDim.x;\n",
        "    int stride_y = blockDim.y * gridDim.y;\n",
        "\n",
        "    for(; row < rows; row += stride_y){\n",
        "        for (int j = col; j < cols; j+= stride_x){\n",
        "            int idx = row * cols + j;\n",
        "            c[idx] = a[idx] + b[idx];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    // Define matrix dimensions\n",
        "    const int ROWS = 100;\n",
        "    const int COLS = 100;\n",
        "    size_t size = ROWS * COLS * sizeof(float);\n",
        "    const dim3 blockSizes[] = {dim3(16, 16), dim3(32, 32)};\n",
        "    int numtests = 2;\n",
        "\n",
        "    // allocate memory for matrices\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    float *h_b = (float *)malloc(size);\n",
        "    float *h_c = (float *)malloc(size);\n",
        "\n",
        "    // Initialize matrices\n",
        "    for (int i = 0; i < ROWS * COLS; i++){\n",
        "        h_a[i] = rand() / (float)RAND_MAX;\n",
        "        h_b[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy matrices from host to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    for (int t=0; t< numtests; t++){\n",
        "        dim3 blockSize = blockSizes[t];\n",
        "        dim3 gridSize((COLS + blockSize.x - 1) / blockSize.x, (ROWS + blockSize.y - 1) / blockSize.y);\n",
        "        printf(\"Testing block size: %dx%d (grid: %d x %d)\\n\", blockSize.x, blockSize.y, gridSize.x, gridSize.y);\n",
        "\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        matrixAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, ROWS, COLS);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"GPU execution time: %.3f ms\\n\", gpu_time);\n",
        "\n",
        "        // Copy result back to host\n",
        "        cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Verify results\n",
        "        printf(\"First 5 result (row 0):/n\");\n",
        "        for (int j=0; j<5; j++){\n",
        "            int idx = 0 * COLS + j;\n",
        "\t\t\tprintf(\"c[0][%d] = %.2f (a[0][%d] = %.2f + b[0][%d] = %.2f)\\n\", j, h_c[idx], j, h_a[idx], j, h_b[idx]);\n",
        "        }\n",
        "\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    // Free host memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wOLwzCN0hRII"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 matrixAddition.cu -o matrixAddition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOPvojexhXVN",
        "outputId": "a01cd710-f66f-4a7c-c987-28e255a92ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing block size: 16x16 (grid: 7 x 7)\n",
            "GPU execution time: 0.124 ms\n",
            "First 5 result (row 0):/nc[0][0] = 1.23 (a[0][0] = 0.84 + b[0][0] = 0.39)\n",
            "c[0][1] = 1.58 (a[0][1] = 0.78 + b[0][1] = 0.80)\n",
            "c[0][2] = 1.11 (a[0][2] = 0.91 + b[0][2] = 0.20)\n",
            "c[0][3] = 1.10 (a[0][3] = 0.34 + b[0][3] = 0.77)\n",
            "c[0][4] = 0.83 (a[0][4] = 0.28 + b[0][4] = 0.55)\n",
            "Testing block size: 32x32 (grid: 4 x 4)\n",
            "GPU execution time: 0.016 ms\n",
            "First 5 result (row 0):/nc[0][0] = 1.23 (a[0][0] = 0.84 + b[0][0] = 0.39)\n",
            "c[0][1] = 1.58 (a[0][1] = 0.78 + b[0][1] = 0.80)\n",
            "c[0][2] = 1.11 (a[0][2] = 0.91 + b[0][2] = 0.20)\n",
            "c[0][3] = 1.10 (a[0][3] = 0.34 + b[0][3] = 0.77)\n",
            "c[0][4] = 0.83 (a[0][4] = 0.28 + b[0][4] = 0.55)\n"
          ]
        }
      ],
      "source": [
        "!./matrixAddition"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
