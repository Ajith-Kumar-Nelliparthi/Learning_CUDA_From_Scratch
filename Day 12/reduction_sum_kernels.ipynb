{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ohVhYH4zD7",
        "outputId": "1b2f4472-aa94-4ee4-af91-8f402248653a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2lbtNgI71bc",
        "outputId": "88fa8d29-fae1-4c9b-d305-83c1808afc75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: %%cuda is a cell magic, but the cell body is empty.\n"
          ]
        }
      ],
      "source": [
        "%%cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvRnQ8aBsOzJ",
        "outputId": "9b29f7a3-1eea-49e8-ac26-0d53b8bdfe17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing reduction_v1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction_v1.cu\n",
        "// Naive interleaved reduction kernel\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce_v1(float *input, float * output, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // load two elements per thread\n",
        "    float sum = 0.0f;\n",
        "    if (idx < n){\n",
        "        sum = input[idx];\n",
        "        if (idx + blockDim.x < n){\n",
        "            sum += input[idx + blockDim.x];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // interleaved reduction . Stride halves every interation\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1){\n",
        "        if (tid < stride){\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        output[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int N = 1 << 20; // 1M elements\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    const int numTests = 3;\n",
        "\n",
        "    float *h_input = (float *)malloc(size);\n",
        "\n",
        "    for (int i=0; i< N; i++){\n",
        "        h_input[i] = 1.0f; // Initialize all elements to 1.0f\n",
        "    }\n",
        "\n",
        "    float *d_input, *d_output;\n",
        "    cudaMalloc((void **)&d_input, size);\n",
        "\n",
        "    for (int t=0; t< numTests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock * 2 - 1) / (threadsPerBlock * 2);\n",
        "\n",
        "        cudaMalloc((void **)&d_output, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v1<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_input, d_output, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess) {\n",
        "            fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v1: %.2f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_output = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_output, d_output, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0.0f;\n",
        "        for (int i = 0; i < blocks; i++) {\n",
        "            final_sum += h_output[i];\n",
        "        }\n",
        "\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "        free(h_output);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    free(h_input);\n",
        "    return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHFkNhmGWHQl"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduction_v1.cu -o reduction_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4gIbVDPWPzi",
        "outputId": "6278c2e9-07de-4b17-fad2-001f6b88850a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 4096)\n",
            "Time taken for v1: 0.24 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 2048)\n",
            "Time taken for v1: 0.07 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 1024)\n",
            "Time taken for v1: 0.07 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduction_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ff7JrQCWS4S",
        "outputId": "924b7431-8c57-4f20-aa0d-5c1df35ceb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing reduction_v2.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction_v2.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce_v2(float *i, float *o, int n){\n",
        "    extern __shared__ float std[];\n",
        "\n",
        "    int tid = threadIdx.x; // thread index within the block\n",
        "    int idx  = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "\n",
        "    // load data into shared memory\n",
        "    float sum = 0.0f;\n",
        "    if (idx < n){\n",
        "        sum = i[idx];\n",
        "        if (idx + blockDim.x < n){\n",
        "            sum += i[idx + blockDim.x];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // store the partial sum in shared memory\n",
        "    std[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // perform reduction in shared memory\n",
        "    for (int stride=1; stride < blockDim.x; stride <<=1){\n",
        "        int index = 2 * stride * tid;\n",
        "        if (index < blockDim.x){\n",
        "            std[index] += std[index + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = std[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int N = 1 << 20; // 1M elements\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    const int numTests = 3;\n",
        "\n",
        "    // Allocate host memory\n",
        "    float *h_i = (float *)malloc(size);\n",
        "    // Initialize input data\n",
        "    for (int i=0; i<N; i++){\n",
        "        h_i[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "\n",
        "    for(int t=0; t<numTests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock * 2 - 1) / (threadsPerBlock * 2);\n",
        "\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_a, h_i, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v2<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0.0f;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v2: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_o = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_o, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for(int i=0; i<blocks; i++){\n",
        "            final_sum += h_o[i];\n",
        "        }\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_o);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "        cudaFree(d_b);\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    free(h_i);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcbQJwEiupTY"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduction_v2.cu -o reduction_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlzEzK9buq71",
        "outputId": "8fc57059-1b46-4f30-fcf1-c7d33c3642dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 4096)\n",
            "Time taken for v2: 0.1401 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 2048)\n",
            "Time taken for v2: 0.0783 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 1024)\n",
            "Time taken for v2: 0.0883 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduction_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_G75-_VutRO",
        "outputId": "df0686cf-d97b-4a90-c19e-3003eb8761e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting reduction_v3.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction_v3.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce_v3(float *i, float *o, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx  = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    if (idx < n){\n",
        "        sum = i[idx];\n",
        "        if (idx + blockDim.x < n){\n",
        "            sum += i[idx + blockDim.x];\n",
        "        }\n",
        "    }\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>=1){\n",
        "        if (tid < stride){\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int N = 1 << 20;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    const int numTests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    for (int i=0; i<N; i++){\n",
        "        h_a[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "\n",
        "    for (int t=0; t<numTests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock * 2 - 1) / (threadsPerBlock * 2);\n",
        "\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v3<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v3: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_b = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for(int i=0; i<blocks; i++){\n",
        "            final_sum += h_b[i];\n",
        "        }\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "        cudaFree(d_b);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olgkiXHOR2Ws"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduction_v3.cu -o reduction_v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5J7txrpR5op",
        "outputId": "b5aa9256-5802-4883-a337-7128769229f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 4096)\n",
            "Time taken for v3: 0.1103 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 2048)\n",
            "Time taken for v3: 0.0661 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 1024)\n",
            "Time taken for v3: 0.0695 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduction_v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA58GKJNR7Uh",
        "outputId": "32780e69-db69-42ba-b282-5cf914140f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting reduction_v4.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction_v4.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce_v4(float *i, float *o, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    if (idx < n){\n",
        "        sum = i[idx];\n",
        "        if (idx + blockDim.x < n){\n",
        "            sum += i[idx + blockDim.x];\n",
        "        }\n",
        "    }\n",
        "    sdata[tid] = sum;\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>=1){\n",
        "      __syncthreads();\n",
        "        if (tid < stride){\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int N = 1 << 20;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    const int numTests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    for (int i=0; i<N; i++){\n",
        "        h_a[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "\n",
        "    for (int t=0; t<numTests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock * 2 - 1) / (threadsPerBlock * 2);\n",
        "\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v4<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v4: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_b = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for(int i=0; i<blocks; i++){\n",
        "            final_sum += h_b[i];\n",
        "        }\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "        cudaFree(d_b);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUOeDCbyZJnw"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduction_v4.cu -o reduction_v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Nnu3hQZK6w",
        "outputId": "f152e5a0-0475-499b-a8ab-ddc43b33e497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 4096)\n",
            "Time taken for v4: 0.1389 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 2048)\n",
            "Time taken for v4: 0.0652 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 1024)\n",
            "Time taken for v4: 0.0694 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduction_v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b91gK30ZNc4",
        "outputId": "398b3ab0-e707-4706-8218-3e75def820ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting reduce_v5.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduce_v5.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce_v5(float *i, float *o, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * (blockDim.x * 8) + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    // load 8 elements per thread\n",
        "    if (idx + 7 * blockDim.x < n){\n",
        "        sum += i[idx];\n",
        "        sum += i[idx + blockDim.x];\n",
        "        sum += i[idx + 2 * blockDim.x];\n",
        "        sum += i[idx + 3 * blockDim.x];\n",
        "        sum += i[idx + 4 * blockDim.x];\n",
        "        sum += i[idx + 5 * blockDim.x];\n",
        "        sum += i[idx + 6 * blockDim.x];\n",
        "        sum += i[idx + 7 * blockDim.x];\n",
        "    }\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1){\n",
        "        if (tid < stride){\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid < 32){\n",
        "        volatile float *vsmem = sdata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid + 8];\n",
        "        vsmem[tid] += vsmem[tid + 4];\n",
        "        vsmem[tid] += vsmem[tid + 2];\n",
        "        vsmem[tid] += vsmem[tid + 1];\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 1 << 20;\n",
        "    size_t size = N * sizeof(float);\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    int numTests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    for (int i=0; i<N; i++){\n",
        "        h_a[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "\n",
        "    for (int t=0; t<numTests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock * 8 - 1) / (threadsPerBlock * 8);\n",
        "\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v5<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v5: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_b = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for(int i=0; i<blocks; i++){\n",
        "            final_sum += h_b[i];\n",
        "        }\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "        cudaFree(d_b);\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewEw_szEBc5F"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduce_v5.cu -o reduce_v5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIsbPXBqBi0D",
        "outputId": "41e64e6c-d564-45ff-912a-5ffa136f3f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 1024)\n",
            "Time taken for v5: 0.1083 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 512)\n",
            "Time taken for v5: 0.0241 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 256)\n",
            "Time taken for v5: 0.0264 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduce_v5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKuYwU_gBln0",
        "outputId": "cc66d139-4554-4370-b149-7f4359cae6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing reduce_v6.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduce_v6.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void reduce_v5(float *i, float *o, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * (blockDim.x * 8) + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    // load 8 elements per thread\n",
        "    if (idx + 7 * blockDim.x < n){\n",
        "        sum += i[idx];\n",
        "        sum += i[idx + blockDim.x];\n",
        "        sum += i[idx + 2 * blockDim.x];\n",
        "        sum += i[idx + 3 * blockDim.x];\n",
        "        sum += i[idx + 4 * blockDim.x];\n",
        "        sum += i[idx + 5 * blockDim.x];\n",
        "        sum += i[idx + 6 * blockDim.x];\n",
        "        sum += i[idx + 7 * blockDim.x];\n",
        "    }\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 1024){\n",
        "        if (tid < 512) sdata[tid] += sdata[tid + 512];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 512){\n",
        "        if (tid < 256) sdata[tid] += sdata[tid + 256];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 256){\n",
        "        if (tid < 128) sdata[tid] += sdata[tid + 128];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 128){\n",
        "        if (tid < 64) sdata[tid] += sdata[tid + 64];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid < 32){\n",
        "        volatile float *vsmem = sdata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid + 8];\n",
        "        vsmem[tid] += vsmem[tid + 4];\n",
        "        vsmem[tid] += vsmem[tid + 2];\n",
        "        vsmem[tid] += vsmem[tid + 1];\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 1 << 20;\n",
        "    size_t size = N * sizeof(float);\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    int numTests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    for (int i=0; i<N; i++){\n",
        "        h_a[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "\n",
        "    for (int t=0; t<numTests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock * 8 - 1) / (threadsPerBlock * 8);\n",
        "\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v5<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v6: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_b = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for(int i=0; i<blocks; i++){\n",
        "            final_sum += h_b[i];\n",
        "        }\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "        cudaFree(d_b);\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad9jatplF1Op"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduce_v6.cu -o reduce_v6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nVVHvNAF261",
        "outputId": "c5dc0880-87cb-4100-a3cf-cae15518cabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 1024)\n",
            "Time taken for v6: 0.1069 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 512)\n",
            "Time taken for v6: 0.0198 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 256)\n",
            "Time taken for v6: 0.0267 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduce_v6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BRO4RzqF4xu",
        "outputId": "e61e2723-18a5-4fb3-b7fa-207cff8947f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing reduce_v7.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduce_v7.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__device__ __forceinline__ float warpReduceSum(float val) {\n",
        "    // __shfl_down_sync(mask, val, delta)\n",
        "    // We use 0xffffffff to indicate all 32 threads in the warp are active\n",
        "    // (In a real scenario with non-multiple-of-32 block sizes, we might need a tighter mask,\n",
        "    // but for standard reductions blockDim is usually a multiple of 32).\n",
        "    for (int offset = warpSize/2; offset > 0; offset >>= 1) {\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    }\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__global__ void reduce_v7(float *i, float *o, int n) {\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    unsigned int tid  = threadIdx.x;\n",
        "    // The Global Index assumes we are processing 8 blocks worth of data per block\n",
        "    unsigned int idx  = blockIdx.x * (blockDim.x * 8) + threadIdx.x;\n",
        "    // The Grid Stride moves by the total number of threads * 8\n",
        "    unsigned int grid = blockDim.x * 8 * gridDim.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // 1. Thread Coarsening Loop (Unrolled x8)\n",
        "    while (idx < n) {\n",
        "        // We must check bounds for every access because N might not be a multiple of the stride\n",
        "        sum += i[idx];\n",
        "        if (idx + blockDim.x < n)      sum += i[idx + blockDim.x];\n",
        "        if (idx + 2 * blockDim.x < n)  sum += i[idx + 2 * blockDim.x];\n",
        "        if (idx + 3 * blockDim.x < n)  sum += i[idx + 3 * blockDim.x];\n",
        "        if (idx + 4 * blockDim.x < n)  sum += i[idx + 4 * blockDim.x];\n",
        "        if (idx + 5 * blockDim.x < n)  sum += i[idx + 5 * blockDim.x];\n",
        "        if (idx + 6 * blockDim.x < n)  sum += i[idx + 6 * blockDim.x];\n",
        "        if (idx + 7 * blockDim.x < n)  sum += i[idx + 7 * blockDim.x];\n",
        "\n",
        "        idx += grid;\n",
        "    }\n",
        "\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // 2. Shared Memory Reduction\n",
        "    // Reduce down to the last 32 threads (1 Warp)\n",
        "    // We stop when stride is 32.\n",
        "    for (int stride = blockDim.x / 2; stride >= 32; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // 3. Warp Shuffle Reduction\n",
        "    // Only the first warp executes this\n",
        "    if (tid < 32) {\n",
        "        float val = sdata[tid];\n",
        "\n",
        "        // Final shared mem reduction before shuffle\n",
        "        // sdata[tid] currently holds partial sum. We need to add the upper half\n",
        "        // if the block was larger than 64.\n",
        "        // Note: The loop above stopped at stride=32, so sdata[0..31] already\n",
        "        // includes the sums from sdata[32..63]. We are good to go.\n",
        "\n",
        "        val = warpReduceSum(val);\n",
        "\n",
        "        if (tid == 0) {\n",
        "            o[blockIdx.x] = val;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1 << 20; // 1M elements\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    int numTests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    // Initialize array to 1.0f. Expected sum = N.\n",
        "    for (int i = 0; i < N; i++) h_a[i] = 1.0f;\n",
        "\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc(&d_a, size);\n",
        "\n",
        "    for (int t = 0; t < numTests; t++) {\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "\n",
        "        // Calculate blocks required given 8x unrolling\n",
        "        int blocks = (N + threadsPerBlock * 8 - 1) / (threadsPerBlock * 8);\n",
        "        // Small safeguard against empty grids\n",
        "        if (blocks == 0) blocks = 1;\n",
        "\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (Grid size: %d)\\n\",\n",
        "               threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        reduce_v7<<<blocks, threadsPerBlock,\n",
        "                    threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float gpu_time;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"Time taken for v7: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "        float *h_b = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for (int i = 0; i < blocks; i++) final_sum += h_b[i];\n",
        "\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_b);\n",
        "        cudaFree(d_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHtXPGF2MY9I"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduce_v7.cu -o reduce_v7.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YRCWh_xMfm3",
        "outputId": "3a5555c5-2ef9-49cf-b152-bf069f60ee67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (Grid size: 1024)\n",
            "Time taken for v7: 0.1332 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (Grid size: 512)\n",
            "Time taken for v7: 0.0217 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (Grid size: 256)\n",
            "Time taken for v7: 0.0272 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduce_v7.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URgzreiEMhsO",
        "outputId": "9fcb20a7-d236-4296-8951-14ddba60df6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting reduce_V8.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduce_V8.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__inline__ __device__ float warpReduceSum(float val){\n",
        "    for (int offset = warpSize/2; offset > 0; offset >>= 1){\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    }\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__global__ void reduce_v8(const float *i, float *o, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    // Cast input to float4 for vectorized loads\n",
        "    const float4 *in_vec = reinterpret_cast<const float4*>(i);\n",
        "    int num_vec = n / 4;\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    // Each thread processes 8 floats = 2 float4 vectors per iteration\n",
        "    int idx = blockIdx.x * (blockDim.x * 2) + tid;\n",
        "    int stride = blockDim.x * 2 * gridDim.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Grid-stride loop: each iteration processes 2 float4 vectors (8 floats)\n",
        "    while (idx < num_vec){\n",
        "        // Load first float4 (4 floats)\n",
        "        float4 v1 = in_vec[idx];\n",
        "        sum += (v1.x + v1.y + v1.z + v1.w);\n",
        "\n",
        "        // Load second float4 (4 more floats) if available\n",
        "        if (idx + blockDim.x < num_vec){\n",
        "            float4 v2 = in_vec[idx + blockDim.x];\n",
        "            sum += (v2.x + v2.y + v2.z + v2.w);\n",
        "        }\n",
        "\n",
        "        idx += stride;\n",
        "    }\n",
        "\n",
        "    // Handle tail elements (if n is not divisible by 4)\n",
        "    // Start from the last complete float4 position\n",
        "    int tail_start = num_vec * 4;\n",
        "    for (int k = tail_start + tid; k < n; k += blockDim.x){\n",
        "        sum += i[k];\n",
        "    }\n",
        "\n",
        "    // Write partial sum to shared memory\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Block reduction in shared memory\n",
        "    for (int s = blockDim.x/2; s >= 32; s >>= 1){\n",
        "        if (tid < s){\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Warp reduction\n",
        "    float val = sdata[tid];\n",
        "    if (tid < 32){\n",
        "        val = warpReduceSum(val);\n",
        "    }\n",
        "\n",
        "    // Write block result\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1 << 20;  // 1M\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    const int numTests = 3;\n",
        "\n",
        "    float *h_a = (float*)malloc(size);\n",
        "    for (int i = 0; i < N; i++)\n",
        "        h_a[i] = 1.0f;\n",
        "\n",
        "    float *d_a;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    for (int t = 0; t < numTests; t++) {\n",
        "        int threads = blockSizes[t];\n",
        "        // Calculate blocks: each thread processes 8 floats = 2 float4s\n",
        "        int blocks = (N + threads*8 - 1) / (threads*8);\n",
        "\n",
        "        float *d_b;\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reduce_v8<<<blocks, threads, threads * sizeof(float)>>>(\n",
        "            d_a, d_b, N\n",
        "        );\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // Check for errors\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess) {\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "        }\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "\n",
        "        float *h_b = (float*)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        float final_sum = 0;\n",
        "        for (int i = 0; i < blocks; i++) final_sum += h_b[i];\n",
        "\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threads, blocks);\n",
        "        printf(\"Time taken for v8 (vectorized): %.4f ms\\n\", gpu_time);\n",
        "        printf(\"Final Sum = %.0f (expected %d)\\n\", final_sum, N);\n",
        "\n",
        "        free(h_b);\n",
        "        cudaFree(d_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wSacxLllf6IB"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduce_V8.cu -o reduce_V8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0kQrfNMf9kv",
        "outputId": "d829317b-81d4-476e-c773-a738a4758111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 1024)\n",
            "Time taken for v8 (vectorized): 0.1268 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 256 (blocks: 512)\n",
            "Time taken for v8 (vectorized): 0.0312 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n",
            "\n",
            "Testing block size: 512 (blocks: 256)\n",
            "Time taken for v8 (vectorized): 0.0344 ms\n",
            "Final Sum = 1048576 (expected 1048576)\n"
          ]
        }
      ],
      "source": [
        "!./reduce_V8"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
