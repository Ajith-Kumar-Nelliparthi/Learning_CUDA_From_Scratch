{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOFljCzmqp-J",
        "outputId": "43db79a2-e77b-4b21-e2d1-7fdda13595cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing matrixMultiled.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrixMultiled.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Tiled matrix multiplication kernel\n",
        "__global__ void matrixMulTiled(const float *a, float *b, float *c, int cols, int rows, int k_dim){\n",
        "    extern __shared__ float shared_mem[];\n",
        "    int tile_size = blockDim.x;\n",
        "    float *tile_A = shared_mem;\n",
        "    float *tile_B = &shared_mem[tile_size * tile_size];\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // loop over the matrix in steps of tile_size\n",
        "    for (int t=0; t< k_dim; t+= tile_size){\n",
        "        // load tile A, row must be valid and the column (t + threadIdx.x ,must be within k_dim)\n",
        "        if (row < rows && (t + threadIdx.x) < k_dim){\n",
        "            tile_A[threadIdx.y * tile_size + threadIdx.x] = a[row * k_dim + (t + threadIdx.x)];\n",
        "        } else {\n",
        "            tile_A[threadIdx.y * tile_size + threadIdx.x] = 0.0f;\n",
        "        }\n",
        "\n",
        "        // load tile B, column must be valid and the row (t + threadIdx.y) must be within k_dim\n",
        "        if (col < cols && (t + threadIdx.y) < k_dim){\n",
        "            tile_B[threadIdx.y * tile_size + threadIdx.x] = b[(t + threadIdx.y) * cols + col];\n",
        "        } else {\n",
        "            tile_B[threadIdx.y * tile_size + threadIdx.x] = 0.0f;\n",
        "        }\n",
        "\n",
        "        // wait for all threads to load their data\n",
        "        __syncthreads();\n",
        "\n",
        "        // compute matrix multiplication for the tile\n",
        "        for (int k=0; k<tile_size; ++k){\n",
        "            sum += tile_A[threadIdx.y * tile_size + k] * tile_B[k * tile_size + threadIdx.x];\n",
        "        }\n",
        "\n",
        "        // wait for all threads to finish computing before loading new tiles\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write the result\n",
        "    if (row < rows && col < cols){\n",
        "        c[row * cols + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int ROWS = 100;\n",
        "    const int COLS = 100;\n",
        "    const int K_DIM = 100;\n",
        "    size_t size = ROWS * COLS * sizeof(float);\n",
        "    const dim3 blockSizes[] = {dim3(16, 16), dim3(32, 32)};\n",
        "    const int numTests = 2;\n",
        "\n",
        "    // Allocate host memory\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    float *h_b = (float *)malloc(size);\n",
        "    float *h_c = (float *)malloc(size);\n",
        "\n",
        "    // Initialize matrices\n",
        "    for (int i=0; i< ROWS * K_DIM; i++){\n",
        "        h_a[i] = rand() / (float)RAND_MAX;\n",
        "        h_b[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy matrices to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    for (int t=0; t< numTests; t++){\n",
        "        dim3 blockSize = blockSizes[t];\n",
        "        dim3 gridSize((COLS + blockSize.x - 1) / blockSize.x,\n",
        "        (ROWS + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "        size_t sharedMemSize = 2 * blockSize.x * blockSize.y * sizeof(float);\n",
        "        printf(\"\\nTesting block size: %dx%d (grid: %dx%d, shared mem: %zu bytes)\\n\", blockSize.x, blockSize.y, gridSize.x, gridSize.y, sharedMemSize);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        matrixMulTiled<<<gridSize, blockSize, sharedMemSize>>>(d_a, d_b, d_c, COLS, ROWS, K_DIM);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"GPU execution time: %.3f ms\\n\", gpu_time);\n",
        "\n",
        "        cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "        printf(\"First 5 results (row 0):\\n\");\n",
        "        for (int j=0; j< 5; j++){\n",
        "            int idx = 0 * COLS + j;\n",
        "            printf(\"C[0][%d] = %.2f\\n\", j, h_c[idx]);\n",
        "        }\n",
        "\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    // Free host memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ducSp86VsFsk"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 matrixMultiled.cu -o matrixMultiled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnlyx_S3sMNZ",
        "outputId": "0e6eb98a-1924-4eac-b4f4-2ca4a3db2017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 16x16 (grid: 7x7, shared mem: 2048 bytes)\n",
            "GPU execution time: 0.159 ms\n",
            "First 5 results (row 0):\n",
            "C[0][0] = 24.76\n",
            "C[0][1] = 25.37\n",
            "C[0][2] = 23.26\n",
            "C[0][3] = 25.60\n",
            "C[0][4] = 21.85\n",
            "\n",
            "Testing block size: 32x32 (grid: 4x4, shared mem: 8192 bytes)\n",
            "GPU execution time: 0.048 ms\n",
            "First 5 results (row 0):\n",
            "C[0][0] = 24.76\n",
            "C[0][1] = 25.37\n",
            "C[0][2] = 23.26\n",
            "C[0][3] = 25.60\n",
            "C[0][4] = 21.85\n"
          ]
        }
      ],
      "source": [
        "!./matrixMultiled"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
