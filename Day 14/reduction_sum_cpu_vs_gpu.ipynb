{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHz5EVG3iL_",
        "outputId": "d211ac8f-311d-482d-822a-9c76725ddb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting reduceSumCPUvsGPU.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduceSumCPUvsGPU.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "\n",
        "__inline__ __device__ float warpReduceSum(float val){\n",
        "    for (int offset = warpSize/2; offset > 0; offset >>= 1){\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    }\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__global__ void reduceSumGPU(const float *i, float *o, int n){\n",
        "    extern __shared__ float sdata[];\n",
        "    const float4 *in_vec = reinterpret_cast<const float4*>(i);\n",
        "    int num_vec = n / 4;\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * (blockDim.x * 2) + tid;\n",
        "    int stride = blockDim.x * 2 * gridDim.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Grid stride loop\n",
        "    while (idx < num_vec){\n",
        "        float4 v1 = in_vec[idx];\n",
        "        sum += v1.x + v1.y + v1.z + v1.w;\n",
        "        if (idx + blockDim.x < num_vec){\n",
        "            float4 v2 = in_vec[idx + blockDim.x];\n",
        "            sum += v2.x + v2.y + v2.z + v2.w;\n",
        "        }\n",
        "        idx += stride;\n",
        "    }\n",
        "    // handle tail elements (not multiple of 4)\n",
        "    int tail_start = num_vec * 4;\n",
        "    for (int k= tail_start + tid; k<n; k+=blockDim.x){\n",
        "        sum += i[k];\n",
        "    }\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // do reduction in shared mem\n",
        "    for (int s= blockDim.x/2; s>=32; s>>=1){\n",
        "        if (tid < s){\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    float val = sdata[tid];\n",
        "    if (tid < 32){\n",
        "        val = warpReduceSum(val);\n",
        "    }\n",
        "\n",
        "    if (tid == 0){\n",
        "        o[blockIdx.x] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "float reduceSumCPU(const float *A, int N){\n",
        "    float sum = 0.0f;\n",
        "    for (int i=0; i<N; i++){\n",
        "        sum += A[i];\n",
        "    }\n",
        "    return sum;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    const int N = 1 << 20;\n",
        "    size_t size_in_bytes = N * sizeof(float);\n",
        "    const int blockSizes[] = {128, 256, 512};\n",
        "    const int numtests = 3;\n",
        "\n",
        "    float *h_a = (float *)malloc(size_in_bytes);\n",
        "    for (int i=0; i<N; i++){\n",
        "        h_a[i] = 1.0f;\n",
        "    }\n",
        "    float *d_a;\n",
        "    cudaMalloc(&d_a, size_in_bytes);\n",
        "    cudaMemcpy(d_a, h_a, size_in_bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    for (int t=0; t<numtests; t++){\n",
        "        int threadsPerBlock = blockSizes[t];\n",
        "        int blocks = (N + threadsPerBlock*8 - 1) / (threadsPerBlock * 8);\n",
        "\n",
        "        float *d_b;\n",
        "        cudaMalloc(&d_b, blocks * sizeof(float));\n",
        "        printf(\"\\nTesting block size: %d (blocks: %d)\\n\", threadsPerBlock, blocks);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reduceSumGPU<<<blocks, threadsPerBlock, threadsPerBlock * sizeof(float)>>>(d_a, d_b, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        cudaError_t err = cudaGetLastError();\n",
        "        if (err != cudaSuccess){\n",
        "            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "            return -1;\n",
        "        }\n",
        "        float gpu_time = 0;\n",
        "        cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "        printf(\"GPU execution time: %.3f ms\\n\", gpu_time);\n",
        "        float *h_b = (float *)malloc(blocks * sizeof(float));\n",
        "        cudaMemcpy(h_b, d_b, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "        float gpu_sum = 0.0f;\n",
        "        for (int i=0; i< blocks; i++){\n",
        "            gpu_sum += h_b[i];\n",
        "        }\n",
        "        printf(\"GPU Sum = %.0f (expected %d)\\n\", gpu_sum, N);\n",
        "\n",
        "        auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "        float cpu_sum_check = reduceSumCPU(h_a, N);\n",
        "        auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "        float cpu_time = std::chrono::duration<float, std::milli>(cpu_end - cpu_start).count();\n",
        "        printf(\"CPU execution time: %.3f ms\\n\", cpu_time);\n",
        "\t\tprintf(\"CPU sum: %.2f\\n\", cpu_sum_check);\n",
        "\n",
        "\t\tif (fabs(gpu_sum - cpu_sum_check) < 1e-3) {\n",
        "\t\t\tprintf(\"Reduction sum completed successfully\\n\");\n",
        "\t\t\tprintf(\"speedup: %.2fX\\n\", cpu_time / gpu_time);\n",
        "\t\t}\n",
        "        free(h_b);\n",
        "        cudaFree(d_b);\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "    cudaFree(d_a);\n",
        "    free(h_a);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eNUaD-nz3nw5"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 reduceSumCPUvsGPU.cu -o reducedSumCPUvsGPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viJGruA43xqG",
        "outputId": "bfee5e21-22ac-4d42-80ef-830d9309d140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing block size: 128 (blocks: 1024)\n",
            "GPU execution time: 0.149 ms\n",
            "GPU Sum = 1048576 (expected 1048576)\n",
            "CPU execution time: 3.030 ms\n",
            "CPU sum: 1048576.00\n",
            "Reduction sum completed successfully\n",
            "speedup: 20.35X\n",
            "\n",
            "Testing block size: 256 (blocks: 512)\n",
            "GPU execution time: 0.035 ms\n",
            "GPU Sum = 1048576 (expected 1048576)\n",
            "CPU execution time: 3.020 ms\n",
            "CPU sum: 1048576.00\n",
            "Reduction sum completed successfully\n",
            "speedup: 86.19X\n",
            "\n",
            "Testing block size: 512 (blocks: 256)\n",
            "GPU execution time: 0.036 ms\n",
            "GPU Sum = 1048576 (expected 1048576)\n",
            "CPU execution time: 2.998 ms\n",
            "CPU sum: 1048576.00\n",
            "Reduction sum completed successfully\n",
            "speedup: 82.55X\n"
          ]
        }
      ],
      "source": [
        "!./reducedSumCPUvsGPU"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
